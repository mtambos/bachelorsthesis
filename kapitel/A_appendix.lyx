#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass book
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding auto
\fontencoding default
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 1
\use_package mhchem 0
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Stichwortverzeichnis
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
\start_of_appendix
Source Code
\begin_inset CommandInset label
LatexCommand label
name "chap:Source-Code"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{
\end_layout

\end_inset

caption=
\begin_inset ERT
status open

\begin_layout Plain Layout

{
\end_layout

\end_inset

mgng.py
\begin_inset ERT
status open

\begin_layout Plain Layout

}}
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "src:mgng_py"

\end_inset

 
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

#!/usr/bin/env python
\end_layout

\begin_layout Plain Layout

# -----------------------------------------------
\end_layout

\begin_layout Plain Layout

# This program is free software: you can redistribute it and/or modify
\end_layout

\begin_layout Plain Layout

# it under the terms of the GNU General Public License version 3 as
\end_layout

\begin_layout Plain Layout

# published by the Free Software Foundation.
\end_layout

\begin_layout Plain Layout

#
\end_layout

\begin_layout Plain Layout

# This program is distributed in the hope that it will be useful,
\end_layout

\begin_layout Plain Layout

# but WITHOUT ANY WARRANTY; without even the implied warranty of
\end_layout

\begin_layout Plain Layout

# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
\end_layout

\begin_layout Plain Layout

# See the GNU General Public License for more details.
\end_layout

\begin_layout Plain Layout

#
\end_layout

\begin_layout Plain Layout

# You should have received a copy of the GNU General Public License
\end_layout

\begin_layout Plain Layout

# along with this program.
  If not, see http://www.gnu.org/licenses.
\end_layout

\begin_layout Plain Layout

# -----------------------------------------------
\end_layout

\begin_layout Plain Layout

'''
\end_layout

\begin_layout Plain Layout

@author: Mario Tambos
\end_layout

\begin_layout Plain Layout

Based on:
\end_layout

\begin_layout Plain Layout

    Andreakis, A.; Hoyningen-Huene, N.
 v.
 & Beetz, M.
\end_layout

\begin_layout Plain Layout

    Incremental unsupervised time series analysis using merge growing neural
 gas
\end_layout

\begin_layout Plain Layout

    Advances in Self-Organizing Maps, Springer, 2009, 10-18
\end_layout

\begin_layout Plain Layout

'''
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

from __future__ import division
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

from numpy.random import random_sample
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

import networkx as nx
\end_layout

\begin_layout Plain Layout

import numpy as np
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def distances(xt, w, c, c_t, alpha):
\end_layout

\begin_layout Plain Layout

    r'''
\end_layout

\begin_layout Plain Layout

    d_n(t) = (1 - 
\backslash
alpha) * ||x_t - w_n||^2 + 
\backslash
alpha||C_t - c_n||^2
\end_layout

\begin_layout Plain Layout

    '''
\end_layout

\begin_layout Plain Layout

    tot = np.sum((1 - alpha)*(xt - w)**2 + alpha*(c_t - c)**2, axis=1)
\end_layout

\begin_layout Plain Layout

    return tot
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def find_winner_neurons(xt, w, c, c_t, alpha):
\end_layout

\begin_layout Plain Layout

    r'''
\end_layout

\begin_layout Plain Layout

    find winner r := arg min_{n 
\backslash
in K} d_n(t)
\end_layout

\begin_layout Plain Layout

    and second winner s := arg min_{n 
\backslash
in K
\backslash
{r}} d_n(t)
\end_layout

\begin_layout Plain Layout

    where d_n(t) = (1 - 
\backslash
alpha) * ||x_t - w_n||^2 + 
\backslash
alpha||C_t - c_n||^2
\end_layout

\begin_layout Plain Layout

    '''
\end_layout

\begin_layout Plain Layout

    dists = distances(xt, w, c, c_t, alpha)
\end_layout

\begin_layout Plain Layout

    r, q = dists.argpartition(1)[:2]
\end_layout

\begin_layout Plain Layout

    return [dists[r], r, dists[q], q]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

class MGNG:
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def __init__(self, dimensions=1, alpha=0.5, beta=0.75, gamma=88,
\end_layout

\begin_layout Plain Layout

                 delta=0.5, theta=100, eta=0.9995, lmbda=600,
\end_layout

\begin_layout Plain Layout

                 e_w=0.05, e_n=0.0006):
\end_layout

\begin_layout Plain Layout

        self.dimensions = dimensions
\end_layout

\begin_layout Plain Layout

        self.alpha = alpha
\end_layout

\begin_layout Plain Layout

        self.beta = beta
\end_layout

\begin_layout Plain Layout

        self.gamma = gamma
\end_layout

\begin_layout Plain Layout

        self.delta = delta
\end_layout

\begin_layout Plain Layout

        self.theta = theta
\end_layout

\begin_layout Plain Layout

        self.eta = eta
\end_layout

\begin_layout Plain Layout

        self.lmbda = lmbda
\end_layout

\begin_layout Plain Layout

        self.e_w = e_w
\end_layout

\begin_layout Plain Layout

        self.e_n = e_n
\end_layout

\begin_layout Plain Layout

        # 4.
 initialize global temporal context C1 := 0
\end_layout

\begin_layout Plain Layout

        self.c_t = np.zeros(dimensions)
\end_layout

\begin_layout Plain Layout

        self.next_n = 0
\end_layout

\begin_layout Plain Layout

        # 1.
 time variable t := 0
\end_layout

\begin_layout Plain Layout

        self.t = 0
\end_layout

\begin_layout Plain Layout

        # 3.
 initialize connections set E 
\backslash
in K * K := 
\backslash
empty;
\end_layout

\begin_layout Plain Layout

        self.model = nx.Graph()
\end_layout

\begin_layout Plain Layout

        self.empty_row = np.array([np.nan]*dimensions)
\end_layout

\begin_layout Plain Layout

        self.weights = np.array([[np.nan]*dimensions]*theta)
\end_layout

\begin_layout Plain Layout

        self.contexts = np.array([[np.nan]*dimensions]*theta)
\end_layout

\begin_layout Plain Layout

        self.errors = np.array([np.nan]*theta)
\end_layout

\begin_layout Plain Layout

        self.matrix_indices = np.zeros(theta)
\end_layout

\begin_layout Plain Layout

        # 2.
 initialize neuron set K with 2 neurons with counter e := 0
\end_layout

\begin_layout Plain Layout

        # and random weight and context vectors
\end_layout

\begin_layout Plain Layout

        self._add_node()
\end_layout

\begin_layout Plain Layout

        self._add_node()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _update_neighbors(self, r, xt):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        update neuron r and its direct topological neighbors N_r:
\end_layout

\begin_layout Plain Layout

            w_r := w_r + 
\backslash
epsilon_w * (x_t - w_r)
\end_layout

\begin_layout Plain Layout

            c_r := c_r + 
\backslash
epsilon_w*(C_t - c_r)
\end_layout

\begin_layout Plain Layout

            (
\backslash
forall n 
\backslash
in N_r)
\end_layout

\begin_layout Plain Layout

                w_n := w_n + 
\backslash
epsilon_n * (x_t - w_i)
\end_layout

\begin_layout Plain Layout

                c_n := c_n + 
\backslash
epsilon_n*(C_t - c_i)
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        w = self.weights[r]
\end_layout

\begin_layout Plain Layout

        c = self.contexts[r]
\end_layout

\begin_layout Plain Layout

        w += self.e_w * (xt - w)
\end_layout

\begin_layout Plain Layout

        c += self.e_w * (self.c_t - c)
\end_layout

\begin_layout Plain Layout

        for n in self.model.neighbors(r):
\end_layout

\begin_layout Plain Layout

            w = self.weights[n]
\end_layout

\begin_layout Plain Layout

            c = self.contexts[n]
\end_layout

\begin_layout Plain Layout

            w += self.e_n * (xt - w)
\end_layout

\begin_layout Plain Layout

            c += self.e_n * (self.c_t - c)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _increment_edges_age(self, r):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        increment the age of all edges connected with r
\end_layout

\begin_layout Plain Layout

            age_{(r,n)} := age_{(r,n)} + 1 (
\backslash
forall n 
\backslash
in N_r )
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        for (u, v) in self.model.edges(r):
\end_layout

\begin_layout Plain Layout

            self.model[u][v]['age'] += 1
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _add_node(self, e=0, w=None, c=None):
\end_layout

\begin_layout Plain Layout

        if w is None:
\end_layout

\begin_layout Plain Layout

            w = random_sample(self.dimensions)
\end_layout

\begin_layout Plain Layout

        else:
\end_layout

\begin_layout Plain Layout

            w = np.reshape(w, newshape=self.dimensions)
\end_layout

\begin_layout Plain Layout

        if c is None:
\end_layout

\begin_layout Plain Layout

            c = random_sample(self.dimensions)
\end_layout

\begin_layout Plain Layout

        else:
\end_layout

\begin_layout Plain Layout

            c = np.reshape(c, newshape=self.dimensions)
\end_layout

\begin_layout Plain Layout

        id = self.matrix_indices.argmin()
\end_layout

\begin_layout Plain Layout

        self.matrix_indices[id] = True
\end_layout

\begin_layout Plain Layout

        self.errors[id] = e
\end_layout

\begin_layout Plain Layout

        self.weights[id] = w
\end_layout

\begin_layout Plain Layout

        self.contexts[id] = c
\end_layout

\begin_layout Plain Layout

        self.model.add_node(id)
\end_layout

\begin_layout Plain Layout

        return id
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _remove_node(self, id):
\end_layout

\begin_layout Plain Layout

        self.matrix_indices[id] = False
\end_layout

\begin_layout Plain Layout

        self.errors[id] = np.nan
\end_layout

\begin_layout Plain Layout

        self.weights[id] = self.empty_row
\end_layout

\begin_layout Plain Layout

        self.contexts[id] = self.empty_row
\end_layout

\begin_layout Plain Layout

        self.model.remove_node(id)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _add_edge(self, r, s):
\end_layout

\begin_layout Plain Layout

        if r == s:
\end_layout

\begin_layout Plain Layout

            raise Exception('cannot connect edge to itself')
\end_layout

\begin_layout Plain Layout

        if s in self.model.neighbors(r):
\end_layout

\begin_layout Plain Layout

            self.model[r][s]['age'] = 0
\end_layout

\begin_layout Plain Layout

        else:
\end_layout

\begin_layout Plain Layout

            self.model.add_edge(r, s, age=0)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _remove_old_edges(self):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        remove old connections E := E 
\backslash
 {(a, b)| age_(a, b) > 
\backslash
gamma}
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        for (u, v) in self.model.edges():
\end_layout

\begin_layout Plain Layout

            if self.model.edge[u][v]['age'] > self.gamma:
\end_layout

\begin_layout Plain Layout

                self.model.remove_edge(u, v)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _remove_unconnected_neurons(self):
\end_layout

\begin_layout Plain Layout

        for n in self.model.nodes():
\end_layout

\begin_layout Plain Layout

            if not self.model.degree(n):
\end_layout

\begin_layout Plain Layout

                self._remove_node(n)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _create_new_neuron(self):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        create new neuron if t mod 
\backslash
lambda = 0 and |K| < 
\backslash
theta
\end_layout

\begin_layout Plain Layout

            a.
 find neuron q with the greatest counter: q := arg max_{n 
\backslash
in K} e_n
\end_layout

\begin_layout Plain Layout

            b.
 find neighbor f of q with f := arg max_{n 
\backslash
in N_q} e_n
\end_layout

\begin_layout Plain Layout

            c.
 initialize new neuron l
\end_layout

\begin_layout Plain Layout

                K := K 
\backslash
cup l
\end_layout

\begin_layout Plain Layout

                w_l := 1/2 * (w_q + w_f)
\end_layout

\begin_layout Plain Layout

                c_l := 1/2 * (c_q + c_f)
\end_layout

\begin_layout Plain Layout

                e_l := 
\backslash
delta * (e_f + e_q)
\end_layout

\begin_layout Plain Layout

            d.
 adapt connections: E := (E 
\backslash
 {(q, f)}) 
\backslash
cup {(q, n), (n, f)}
\end_layout

\begin_layout Plain Layout

            e.
 decrease counter of q and f by the factor 
\backslash
delta
\end_layout

\begin_layout Plain Layout

                e_q := (1 - 
\backslash
deta) * e_q
\end_layout

\begin_layout Plain Layout

                e_f := (1 - 
\backslash
deta) * e_f
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        q = np.nanargmax(self.errors)
\end_layout

\begin_layout Plain Layout

        N_q = None
\end_layout

\begin_layout Plain Layout

        if q:
\end_layout

\begin_layout Plain Layout

            N_q = self.model.neighbors(q)
\end_layout

\begin_layout Plain Layout

        if N_q:
\end_layout

\begin_layout Plain Layout

            f = max(N_q, key=lambda n: self.errors[n])
\end_layout

\begin_layout Plain Layout

            l = self._add_node(e=self.delta*(self.errors[q] + self.errors[f]),
\end_layout

\begin_layout Plain Layout

                               w=(self.weights[q] + self.weights[f]) / 2,
\end_layout

\begin_layout Plain Layout

                               c=(self.contexts[q] + self.contexts[f]) / 2)
\end_layout

\begin_layout Plain Layout

            self.model.remove_edge(q, f)
\end_layout

\begin_layout Plain Layout

            self._add_edge(q, l)
\end_layout

\begin_layout Plain Layout

            self._add_edge(f, l)
\end_layout

\begin_layout Plain Layout

            self.errors[q] *= (1 - self.delta)
\end_layout

\begin_layout Plain Layout

            self.errors[f] *= (1 - self.delta)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

            return l
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def time_step(self, xt):
\end_layout

\begin_layout Plain Layout

        # 6.
 find winner r and second winner s
\end_layout

\begin_layout Plain Layout

        xt = np.reshape(xt, newshape=self.dimensions)
\end_layout

\begin_layout Plain Layout

        winners = find_winner_neurons(xt, self.weights, self.contexts,
\end_layout

\begin_layout Plain Layout

                                      self.c_t, self.alpha)
\end_layout

\begin_layout Plain Layout

        r_dist = winners[0]
\end_layout

\begin_layout Plain Layout

        r = int(winners[1])
\end_layout

\begin_layout Plain Layout

        s_dist = winners[2]
\end_layout

\begin_layout Plain Layout

        s = int(winners[3])
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 7.
 Ct+1 := (1 - 
\backslash
beta)*w_r + 
\backslash
beta*c_r
\end_layout

\begin_layout Plain Layout

        c_t1 = (1 - self.beta) * self.weights[r] + self.beta * self.contexts[r]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 8.
 connect r with s: E := E 
\backslash
cup {(r, s)}
\end_layout

\begin_layout Plain Layout

        # 9.
 age(r;s) := 0
\end_layout

\begin_layout Plain Layout

        self._add_edge(r, s)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 10.
 increment counter of r: e_r := e_r + 1
\end_layout

\begin_layout Plain Layout

        self.errors[r] += 1
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 11.
 update neuron r and its direct topological neighbors:
\end_layout

\begin_layout Plain Layout

        self._update_neighbors(r, xt)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 12.
 increment the age of all edges connected with r
\end_layout

\begin_layout Plain Layout

        self._increment_edges_age(r)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 13.
 remove old connections E := E 
\backslash
 {(a, b)| age_(a, b) > 
\backslash
gamma}
\end_layout

\begin_layout Plain Layout

        self._remove_old_edges()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 14.
 delete all nodes with no connections.
\end_layout

\begin_layout Plain Layout

        self._remove_unconnected_neurons()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 15.
 create new neuron if t mod 
\backslash
lambda = 0 and |K| < 
\backslash
theta
\end_layout

\begin_layout Plain Layout

        if self.t % self.lmbda == 0 and len(self.model.nodes()) < self.theta:
\end_layout

\begin_layout Plain Layout

            self._create_new_neuron()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 16.
 decrease counter of all neurons by the factor 
\backslash
eta:
\end_layout

\begin_layout Plain Layout

        #    e_n := 
\backslash
eta * e_n (
\backslash
forall n 
\backslash
in K)
\end_layout

\begin_layout Plain Layout

        self.errors *= self.eta
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 7.
 Ct+1 := (1 - 
\backslash
beta)*w_r + 
\backslash
beta*c_r
\end_layout

\begin_layout Plain Layout

        self.c_t = c_t1
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 17.
 t := t + 1
\end_layout

\begin_layout Plain Layout

        self.t += 1
\end_layout

\begin_layout Plain Layout

        
\end_layout

\begin_layout Plain Layout

        return r_dist
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{
\end_layout

\end_inset

caption=
\begin_inset ERT
status open

\begin_layout Plain Layout

{
\end_layout

\end_inset

amgng.py
\begin_inset ERT
status open

\begin_layout Plain Layout

}}
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "src:amgng_py"

\end_inset

 
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

#!/usr/bin/env python
\end_layout

\begin_layout Plain Layout

# -----------------------------------------------
\end_layout

\begin_layout Plain Layout

# This program is free software: you can redistribute it and/or modify
\end_layout

\begin_layout Plain Layout

# it under the terms of the GNU General Public License version 3 as
\end_layout

\begin_layout Plain Layout

# published by the Free Software Foundation.
\end_layout

\begin_layout Plain Layout

#
\end_layout

\begin_layout Plain Layout

# This program is distributed in the hope that it will be useful,
\end_layout

\begin_layout Plain Layout

# but WITHOUT ANY WARRANTY; without even the implied warranty of
\end_layout

\begin_layout Plain Layout

# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
\end_layout

\begin_layout Plain Layout

# See the GNU General Public License for more details.
\end_layout

\begin_layout Plain Layout

#
\end_layout

\begin_layout Plain Layout

# You should have received a copy of the GNU General Public License
\end_layout

\begin_layout Plain Layout

# along with this program.
  If not, see http://www.gnu.org/licenses.
\end_layout

\begin_layout Plain Layout

# -----------------------------------------------
\end_layout

\begin_layout Plain Layout

'''
\end_layout

\begin_layout Plain Layout

@author: Mario Tambos
\end_layout

\begin_layout Plain Layout

'''
\end_layout

\begin_layout Plain Layout

from __future__ import division
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

import bottleneck as bn
\end_layout

\begin_layout Plain Layout

import numpy as np
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

import mgng
\end_layout

\begin_layout Plain Layout

from ring_buffer import RingBuffer
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

class AMGNG:
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def __init__(self, comparison_function, buffer_len, dimensions,
\end_layout

\begin_layout Plain Layout

                 prest_gamma, prest_lmbda, prest_theta,
\end_layout

\begin_layout Plain Layout

                 pst_gamma, pst_lmbda, pst_theta,
\end_layout

\begin_layout Plain Layout

                 prest_alpha=0.5, prest_beta=0.5, prest_delta=0.5,
\end_layout

\begin_layout Plain Layout

                 prest_eta=0.9995, prest_e_w=0.05, prest_e_n=0.0006,
\end_layout

\begin_layout Plain Layout

                 pst_alpha=0.5, pst_beta=0.75, pst_delta=0.5,
\end_layout

\begin_layout Plain Layout

                 pst_eta=0.9995, pst_e_w=0.05, pst_e_n=0.0006):
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        self.comparison_function = comparison_function
\end_layout

\begin_layout Plain Layout

        self.buffer_len = buffer_len
\end_layout

\begin_layout Plain Layout

        self.dimensions = dimensions
\end_layout

\begin_layout Plain Layout

        self.present = mgng.MGNG(dimensions=dimensions,
\end_layout

\begin_layout Plain Layout

                                 gamma=int(prest_gamma),
\end_layout

\begin_layout Plain Layout

                                 lmbda=int(prest_lmbda),
\end_layout

\begin_layout Plain Layout

                                 theta=int(prest_theta),
\end_layout

\begin_layout Plain Layout

                                 alpha=float(prest_alpha),
\end_layout

\begin_layout Plain Layout

                                 beta=float(prest_beta),
\end_layout

\begin_layout Plain Layout

                                 delta=float(prest_delta),
\end_layout

\begin_layout Plain Layout

                                 eta=float(prest_eta),
\end_layout

\begin_layout Plain Layout

                                 e_w=float(prest_e_w),
\end_layout

\begin_layout Plain Layout

                                 e_n=float(prest_e_n))
\end_layout

\begin_layout Plain Layout

        self.past = mgng.MGNG(dimensions=dimensions,
\end_layout

\begin_layout Plain Layout

                              gamma=int(pst_gamma),
\end_layout

\begin_layout Plain Layout

                              lmbda=int(pst_lmbda),
\end_layout

\begin_layout Plain Layout

                              theta=int(pst_theta),
\end_layout

\begin_layout Plain Layout

                              alpha=float(pst_alpha),
\end_layout

\begin_layout Plain Layout

                              beta=float(pst_beta),
\end_layout

\begin_layout Plain Layout

                              delta=float(pst_delta),
\end_layout

\begin_layout Plain Layout

                              eta=float(pst_eta),
\end_layout

\begin_layout Plain Layout

                              e_w=float(pst_e_w),
\end_layout

\begin_layout Plain Layout

                              e_n=float(pst_e_n))
\end_layout

\begin_layout Plain Layout

        self.buffer = RingBuffer([[np.nan]*dimensions]*buffer_len)
\end_layout

\begin_layout Plain Layout

        self.t = 0
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def time_step(self, xt):
\end_layout

\begin_layout Plain Layout

        xt = np.reshape(xt, newshape=self.dimensions)
\end_layout

\begin_layout Plain Layout

        ret_val = 0.
\end_layout

\begin_layout Plain Layout

        self.buffer.append(xt)
\end_layout

\begin_layout Plain Layout

        self.present.time_step(xt)
\end_layout

\begin_layout Plain Layout

        if self.t >= self.buffer_len:
\end_layout

\begin_layout Plain Layout

            pst_xt = self.buffer[0]
\end_layout

\begin_layout Plain Layout

            self.past.time_step(pst_xt)
\end_layout

\begin_layout Plain Layout

            if self.t >= self.present.theta + self.past.theta:
\end_layout

\begin_layout Plain Layout

                ret_val = self.comparison_function(self.present, self.past,
\end_layout

\begin_layout Plain Layout

                                                   self.present.alpha)
\end_layout

\begin_layout Plain Layout

        self.t += 1
\end_layout

\begin_layout Plain Layout

        return ret_val
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def compare_models(present_model, past_model, alpha):
\end_layout

\begin_layout Plain Layout

    tot = [0.]
\end_layout

\begin_layout Plain Layout

    ps_w = past_model.weights
\end_layout

\begin_layout Plain Layout

    ps_c = past_model.contexts
\end_layout

\begin_layout Plain Layout

    for pr_x in present_model.model.node:
\end_layout

\begin_layout Plain Layout

        pr_x_w = present_model.weights[pr_x]
\end_layout

\begin_layout Plain Layout

        pr_x_c = present_model.contexts[pr_x]
\end_layout

\begin_layout Plain Layout

        dists = mgng.distances(pr_x_w, ps_w, ps_c, pr_x_w, alpha)
\end_layout

\begin_layout Plain Layout

        ps_x = np.nanargmin(dists)
\end_layout

\begin_layout Plain Layout

        tot += dists[ps_x]
\end_layout

\begin_layout Plain Layout

    return tot[0] / len(present_model.model.nodes())
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_body
\end_document
