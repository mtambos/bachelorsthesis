#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass book
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding auto
\fontencoding default
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 0
\use_mathdots 0
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Stichwortverzeichnis
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
\start_of_appendix
Source Code
\begin_inset CommandInset label
LatexCommand label
name "chap:Source-Code"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{
\end_layout

\end_inset

caption=
\begin_inset ERT
status open

\begin_layout Plain Layout

{
\end_layout

\end_inset

mgng.py
\begin_inset ERT
status open

\begin_layout Plain Layout

}}
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "src:mgng_py"

\end_inset

 
\begin_inset listings
inline false
status collapsed

\begin_layout Plain Layout

from __future__ import print_function, division
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

from collections import defaultdict
\end_layout

\begin_layout Plain Layout

from functools import partial
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

from numpy.random import random_sample
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

import networkx as nx
\end_layout

\begin_layout Plain Layout

import numpy as np
\end_layout

\begin_layout Plain Layout

import numpy.linalg as lnp
\end_layout

\begin_layout Plain Layout

import numexpr as ne
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

class MGNG:
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def __init__(self, dimensions=1, alpha=0.5, beta=0.75, gamma=88,
\end_layout

\begin_layout Plain Layout

                 delta=0.5, theta=100, eta=0.9995, lmbda=600,
\end_layout

\begin_layout Plain Layout

                 e_w=0.05, e_n=0.0006):
\end_layout

\begin_layout Plain Layout

        self.dimensions = dimensions
\end_layout

\begin_layout Plain Layout

        self.alpha = alpha
\end_layout

\begin_layout Plain Layout

        self.beta = beta
\end_layout

\begin_layout Plain Layout

        self.gamma = gamma
\end_layout

\begin_layout Plain Layout

        self.delta = delta
\end_layout

\begin_layout Plain Layout

        self.theta = theta
\end_layout

\begin_layout Plain Layout

        self.eta = eta
\end_layout

\begin_layout Plain Layout

        self.lmbda = lmbda
\end_layout

\begin_layout Plain Layout

        self.e_w = e_w
\end_layout

\begin_layout Plain Layout

        self.e_n = e_n
\end_layout

\begin_layout Plain Layout

        # 4.
 initialize global temporal context C1 := 0
\end_layout

\begin_layout Plain Layout

        self.c_t = np.zeros(dimensions)
\end_layout

\begin_layout Plain Layout

        self.next_n = 0
\end_layout

\begin_layout Plain Layout

        # 1.
 time variable t := 0
\end_layout

\begin_layout Plain Layout

        self.t = 0
\end_layout

\begin_layout Plain Layout

        # 3.
 initialize connections set E 
\backslash
in K * K := 
\backslash
empty;
\end_layout

\begin_layout Plain Layout

        self.model = nx.Graph()
\end_layout

\begin_layout Plain Layout

        self.empty_row = np.array([np.nan]*dimensions)
\end_layout

\begin_layout Plain Layout

        self.weights = np.array([[np.nan]*dimensions]*theta)
\end_layout

\begin_layout Plain Layout

        self.contexts = np.array([[np.nan]*dimensions]*theta)
\end_layout

\begin_layout Plain Layout

        self.errors = np.array([np.nan]*theta)
\end_layout

\begin_layout Plain Layout

        self.matrix_indices = np.zeros(theta)
\end_layout

\begin_layout Plain Layout

        # 2.
 initialize neuron set K with 2 neurons with counter e := 0
\end_layout

\begin_layout Plain Layout

        # and random weight and context vectors
\end_layout

\begin_layout Plain Layout

        self._add_node()
\end_layout

\begin_layout Plain Layout

        self._add_node()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def distances(self, xt):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        d_n(t) = (1 - 
\backslash
alpha) * ||x_t - w_n||^2 + 
\backslash
alpha||C_t - c_n||^2
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        w = self.weights
\end_layout

\begin_layout Plain Layout

        c = self.contexts
\end_layout

\begin_layout Plain Layout

        c_t = self.c_t
\end_layout

\begin_layout Plain Layout

        alpha = self.alpha
\end_layout

\begin_layout Plain Layout

        # tot = ne.evaluate('sum((1 - alpha)*(xt - w)**2 +'
\end_layout

\begin_layout Plain Layout

        #                   '    alpha*(c_t-c)**2, axis=1)')
\end_layout

\begin_layout Plain Layout

        tot = np.add.reduce((1-self.alpha)*(xt-self.weights)**2 +
\end_layout

\begin_layout Plain Layout

                            self.alpha*(self.c_t-self.contexts)**2, axis=1)
\end_layout

\begin_layout Plain Layout

        return tot
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def find_winner_neurons(self, xt):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        find winner r := arg min_{n 
\backslash
in K} d_n(t)
\end_layout

\begin_layout Plain Layout

        and second winner s := arg min_{n 
\backslash
in K
\backslash
{r}} d_n(t)
\end_layout

\begin_layout Plain Layout

        where d_n(t) = (1 - 
\backslash
alpha) * ||x_t - w_n||^2 + 
\backslash
alpha||C_t - c_n||^2
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        distances = self.distances(xt)
\end_layout

\begin_layout Plain Layout

        r, q = distances.argpartition(1)[:2]
\end_layout

\begin_layout Plain Layout

        return (distances[r], r), (distances[q], q)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _update_neighbors(self, r, xt):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        update neuron r and its direct topological neighbors N_r:
\end_layout

\begin_layout Plain Layout

            w_r := w_r + 
\backslash
epsilon_w * (x_t - w_r)
\end_layout

\begin_layout Plain Layout

            c_r := c_r + 
\backslash
epsilon_w*(C_t - c_r)
\end_layout

\begin_layout Plain Layout

            (
\backslash
forall n 
\backslash
in N_r)
\end_layout

\begin_layout Plain Layout

                w_n := w_n + 
\backslash
epsilon_n * (x_t - w_i)
\end_layout

\begin_layout Plain Layout

                c_n := c_n + 
\backslash
epsilon_n*(C_t - c_i)
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        w = self.weights[r]
\end_layout

\begin_layout Plain Layout

        c = self.contexts[r]
\end_layout

\begin_layout Plain Layout

        w += self.e_w * (xt - w)
\end_layout

\begin_layout Plain Layout

        c += self.e_w * (self.c_t - c)
\end_layout

\begin_layout Plain Layout

        for n in self.model.neighbors(r):
\end_layout

\begin_layout Plain Layout

            w = self.weights[n]
\end_layout

\begin_layout Plain Layout

            c = self.contexts[n]
\end_layout

\begin_layout Plain Layout

            w += self.e_n * (xt - w)
\end_layout

\begin_layout Plain Layout

            c += self.e_n * (self.c_t - c)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _increment_edges_age(self, r):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        increment the age of all edges connected with r
\end_layout

\begin_layout Plain Layout

            age_{(r,n)} := age_{(r,n)} + 1 (
\backslash
forall n 
\backslash
in N_r )
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        for (u, v) in self.model.edges(r):
\end_layout

\begin_layout Plain Layout

            self.model[u][v]['age'] += 1
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _add_node(self, e=0, w=None, c=None):
\end_layout

\begin_layout Plain Layout

        if w is None:
\end_layout

\begin_layout Plain Layout

            w = random_sample(self.dimensions)
\end_layout

\begin_layout Plain Layout

        else:
\end_layout

\begin_layout Plain Layout

            w = np.reshape(w, newshape=self.dimensions)
\end_layout

\begin_layout Plain Layout

        if c is None:
\end_layout

\begin_layout Plain Layout

            c = random_sample(self.dimensions)
\end_layout

\begin_layout Plain Layout

        else:
\end_layout

\begin_layout Plain Layout

            c = np.reshape(c, newshape=self.dimensions)
\end_layout

\begin_layout Plain Layout

        id = self.matrix_indices.argmin()
\end_layout

\begin_layout Plain Layout

        self.matrix_indices[id] = True
\end_layout

\begin_layout Plain Layout

        self.errors[id] = e
\end_layout

\begin_layout Plain Layout

        self.weights[id] = w
\end_layout

\begin_layout Plain Layout

        self.contexts[id] = c
\end_layout

\begin_layout Plain Layout

        self.model.add_node(id)
\end_layout

\begin_layout Plain Layout

        print('Node {} added.'.format(id))
\end_layout

\begin_layout Plain Layout

        return id
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _remove_node(self, id):
\end_layout

\begin_layout Plain Layout

        self.matrix_indices[id] = False
\end_layout

\begin_layout Plain Layout

        self.errors[id] = np.nan
\end_layout

\begin_layout Plain Layout

        self.weights[id] = self.empty_row
\end_layout

\begin_layout Plain Layout

        self.contexts[id] = self.empty_row
\end_layout

\begin_layout Plain Layout

        self.model.remove_node(id)
\end_layout

\begin_layout Plain Layout

        print('Node {} removed.'.format(id))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _add_edge(self, r, s):
\end_layout

\begin_layout Plain Layout

        if r == s:
\end_layout

\begin_layout Plain Layout

            raise Exception('cannot connect edge to itself')
\end_layout

\begin_layout Plain Layout

        if s in self.model.neighbors(r):
\end_layout

\begin_layout Plain Layout

            self.model[r][s]['age'] = 0
\end_layout

\begin_layout Plain Layout

        else:
\end_layout

\begin_layout Plain Layout

            self.model.add_edge(r, s, age=0)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _remove_old_edges(self):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        remove old connections E := E 
\backslash
 {(a, b)| age_(a, b) > 
\backslash
gamma}
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        for (u, v) in self.model.edges():
\end_layout

\begin_layout Plain Layout

            if self.model.edge[u][v]['age'] > self.gamma:
\end_layout

\begin_layout Plain Layout

                self.model.remove_edge(u, v)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _remove_unconnected_neurons(self):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        for n in self.model.nodes():
\end_layout

\begin_layout Plain Layout

            if not self.model.degree(n):
\end_layout

\begin_layout Plain Layout

                self._remove_node(n)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def _create_new_neuron(self):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        create new neuron if t mod 
\backslash
lambda = 0 and |K| < 
\backslash
theta
\end_layout

\begin_layout Plain Layout

            a.
 find neuron q with the greatest counter: q := arg max_{n 
\backslash
in K} e_n
\end_layout

\begin_layout Plain Layout

            b.
 find neighbor f of q with f := arg max_{n 
\backslash
in N_q} e_n
\end_layout

\begin_layout Plain Layout

            c.
 initialize new neuron l
\end_layout

\begin_layout Plain Layout

                K := K 
\backslash
cup l
\end_layout

\begin_layout Plain Layout

                w_l := 1/2 * (w_q + w_f)
\end_layout

\begin_layout Plain Layout

                c_l := 1/2 * (c_q + c_f)
\end_layout

\begin_layout Plain Layout

                e_l := 
\backslash
delta * (e_f + e_q)
\end_layout

\begin_layout Plain Layout

            d.
 adapt connections: E := (E 
\backslash
 {(q, f)}) 
\backslash
cup {(q, n), (n, f)}
\end_layout

\begin_layout Plain Layout

            e.
 decrease counter of q and f by the factor 
\backslash
delta
\end_layout

\begin_layout Plain Layout

                e_q := (1 - 
\backslash
deta) * e_q
\end_layout

\begin_layout Plain Layout

                e_f := (1 - 
\backslash
deta) * e_f
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        q = np.nanargmax(self.errors)
\end_layout

\begin_layout Plain Layout

        N_q = None
\end_layout

\begin_layout Plain Layout

        if q:
\end_layout

\begin_layout Plain Layout

            N_q = self.model.neighbors(q)
\end_layout

\begin_layout Plain Layout

        if N_q:
\end_layout

\begin_layout Plain Layout

            f = max(N_q, key=lambda n: self.errors[n])
\end_layout

\begin_layout Plain Layout

            l = self._add_node(e=self.delta*(self.errors[q] + self.errors[f]),
\end_layout

\begin_layout Plain Layout

                               w=(self.weights[q] + self.weights[f]) / 2,
\end_layout

\begin_layout Plain Layout

                               c=(self.contexts[q] + self.contexts[f]) / 2)
\end_layout

\begin_layout Plain Layout

            self.model.remove_edge(q, f)
\end_layout

\begin_layout Plain Layout

            self._add_edge(q, l)
\end_layout

\begin_layout Plain Layout

            self._add_edge(f, l)
\end_layout

\begin_layout Plain Layout

            self.errors[q] *= (1 - self.delta)
\end_layout

\begin_layout Plain Layout

            self.errors[f] *= (1 - self.delta)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

            return l
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def time_step(self, xt):
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        '''
\end_layout

\begin_layout Plain Layout

        # 6.
 find winner r and second winner s
\end_layout

\begin_layout Plain Layout

        xt = np.reshape(xt, newshape=self.dimensions)
\end_layout

\begin_layout Plain Layout

        r, s = self.find_winner_neurons(xt)
\end_layout

\begin_layout Plain Layout

        r_dist, r = r
\end_layout

\begin_layout Plain Layout

        s_dist, s = s
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 7.
 Ct+1 := (1 - 
\backslash
beta)*w_r + 
\backslash
beta*c_r
\end_layout

\begin_layout Plain Layout

        c_t1 = (1 - self.beta) * self.weights[r] + self.beta * self.contexts[r]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 8.
 connect r with s: E := E 
\backslash
cup {(r, s)}
\end_layout

\begin_layout Plain Layout

        # 9.
 age(r;s) := 0
\end_layout

\begin_layout Plain Layout

        self._add_edge(r, s)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 10.
 increment counter of r: e_r := e_r + 1
\end_layout

\begin_layout Plain Layout

        self.errors[r] += 1
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 11.
 update neuron r and its direct topological neighbors:
\end_layout

\begin_layout Plain Layout

        self._update_neighbors(r, xt)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 12.
 increment the age of all edges connected with r
\end_layout

\begin_layout Plain Layout

        self._increment_edges_age(r)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 13.
 remove old connections E := E 
\backslash
 {(a, b)| age_(a, b) > 
\backslash
gamma}
\end_layout

\begin_layout Plain Layout

        self._remove_old_edges()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 14.
 delete all nodes with no connections.
\end_layout

\begin_layout Plain Layout

        self._remove_unconnected_neurons()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 15.
 create new neuron if t mod 
\backslash
lambda = 0 and |K| < 
\backslash
theta
\end_layout

\begin_layout Plain Layout

        if self.t % self.lmbda == 0 and len(self.model.nodes()) < self.theta:
\end_layout

\begin_layout Plain Layout

            self._create_new_neuron()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 16.
 decrease counter of all neurons by the factor 
\backslash
eta:
\end_layout

\begin_layout Plain Layout

        #    e_n := 
\backslash
eta * e_n (
\backslash
forall n 
\backslash
in K)
\end_layout

\begin_layout Plain Layout

        self.errors *= self.eta
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 7.
 Ct+1 := (1 - 
\backslash
beta)*w_r + 
\backslash
beta*c_r
\end_layout

\begin_layout Plain Layout

        self.c_t = c_t1
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        # 17.
 t := t + 1
\end_layout

\begin_layout Plain Layout

        self.t += 1
\end_layout

\begin_layout Plain Layout

        
\end_layout

\begin_layout Plain Layout

        return r_dist
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def main():
\end_layout

\begin_layout Plain Layout

    import Oger as og
\end_layout

\begin_layout Plain Layout

    import pylab
\end_layout

\begin_layout Plain Layout

    signal = og.datasets.mackey_glass(sample_len=1500,
\end_layout

\begin_layout Plain Layout

                                      n_samples=1,
\end_layout

\begin_layout Plain Layout

                                      seed=50)[0][0].flatten()
\end_layout

\begin_layout Plain Layout

    print(signal)
\end_layout

\begin_layout Plain Layout

    signal = signal + np.abs(signal.min())
\end_layout

\begin_layout Plain Layout

    print(signal)
\end_layout

\begin_layout Plain Layout

    # 2.
 initialize neuron set K with 2 neurons with counter e := 0 and random weight
 and context vectors
\end_layout

\begin_layout Plain Layout

    # 3.
 initialize connections set E 
\backslash
in K * K := 
\backslash
empty;
\end_layout

\begin_layout Plain Layout

    # 4.
 initialize global temporal context C1 := 0
\end_layout

\begin_layout Plain Layout

    mgng = MGNG(lmbda=6)
\end_layout

\begin_layout Plain Layout

    # 1.
 time variable t := 1
\end_layout

\begin_layout Plain Layout

    # 5.
 read / draw input signal xt
\end_layout

\begin_layout Plain Layout

    # 18.
 if more input signals available goto step 5 else terminate
\end_layout

\begin_layout Plain Layout

    for t, xt in enumerate(signal, 1):
\end_layout

\begin_layout Plain Layout

        mgng.time_step(xt)
\end_layout

\begin_layout Plain Layout

        if t % 1500 == 0:
\end_layout

\begin_layout Plain Layout

            print('training: %i%%' % (t / 1500))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    errors = [[] for _ in range(30)]
\end_layout

\begin_layout Plain Layout

    for t, xt in enumerate(signal, 1):
\end_layout

\begin_layout Plain Layout

        if t % 150 == 0:
\end_layout

\begin_layout Plain Layout

            print('calculating errors: %i%%' % (t / 150))
\end_layout

\begin_layout Plain Layout

        n, _ = mgng.find_winner_neurons(xt)
\end_layout

\begin_layout Plain Layout

        n = n[1] 
\end_layout

\begin_layout Plain Layout

        for i in range(min(30, t)):
\end_layout

\begin_layout Plain Layout

            errors[i].append((n['w'] - signal[t - i - 1]) ** 2)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    summary = [0] * 30
\end_layout

\begin_layout Plain Layout

    for i in range(30):
\end_layout

\begin_layout Plain Layout

        summary[i] = np.sum(errors[i]) / len(errors[i])
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    pylab.subplot(2, 1, 1)
\end_layout

\begin_layout Plain Layout

    pylab.plot(range(30), summary)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    pylab.subplot(2, 1, 2)
\end_layout

\begin_layout Plain Layout

    pylab.plot(range(len(mgng.model.nodes())),
\end_layout

\begin_layout Plain Layout

               [n[1]['w'] for n in mgng.model.nodes(data=True)])
\end_layout

\begin_layout Plain Layout

    pylab.show()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

if __name__ == '__main__':
\end_layout

\begin_layout Plain Layout

    import sys
\end_layout

\begin_layout Plain Layout

    
\end_layout

\begin_layout Plain Layout

    if len(sys.argv) > 1:
\end_layout

\begin_layout Plain Layout

        main(sys.argv[1])
\end_layout

\begin_layout Plain Layout

    else:
\end_layout

\begin_layout Plain Layout

        main()
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{
\end_layout

\end_inset

caption=
\begin_inset ERT
status open

\begin_layout Plain Layout

{
\end_layout

\end_inset

amgng.py
\begin_inset ERT
status open

\begin_layout Plain Layout

}}
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "src:amgng_py"

\end_inset

 
\begin_inset listings
inline false
status collapsed

\begin_layout Plain Layout

from __future__ import division, print_function
\end_layout

\begin_layout Plain Layout

from collections import deque
\end_layout

\begin_layout Plain Layout

import inspect
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

from ring_buffer import RingBuffer
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

import mgng
\end_layout

\begin_layout Plain Layout

import numpy as np
\end_layout

\begin_layout Plain Layout

import numexpr as ne
\end_layout

\begin_layout Plain Layout

import numpy.linalg as lnp
\end_layout

\begin_layout Plain Layout

from scipy.stats import norm
\end_layout

\begin_layout Plain Layout

import bottleneck as bn
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

class AMGNG:
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def __init__(self, comparison_function, buffer_len, dimensions,
\end_layout

\begin_layout Plain Layout

                 prest_gamma, prest_lmbda, prest_theta,
\end_layout

\begin_layout Plain Layout

                 pst_gamma, pst_lmbda, pst_theta,
\end_layout

\begin_layout Plain Layout

                 prest_alpha=0.5, prest_beta=0.5, prest_delta=0.5,
\end_layout

\begin_layout Plain Layout

                 prest_eta=0.9995, prest_e_w=0.05, prest_e_n=0.0006,
\end_layout

\begin_layout Plain Layout

                 pst_alpha=0.5, pst_beta=0.75, pst_delta=0.5,
\end_layout

\begin_layout Plain Layout

                 pst_eta=0.9995, pst_e_w=0.05, pst_e_n=0.0006,
\end_layout

\begin_layout Plain Layout

                 ma_window_len=None, ma_recalc_delay=1):
\end_layout

\begin_layout Plain Layout

        values = inspect.getargvalues(inspect.currentframe())[3]
\end_layout

\begin_layout Plain Layout

        print('Init parameters: {}'.format(values))
\end_layout

\begin_layout Plain Layout

        self.comparison_function = comparison_function
\end_layout

\begin_layout Plain Layout

        self.buffer_len = buffer_len
\end_layout

\begin_layout Plain Layout

        self.dimensions = dimensions
\end_layout

\begin_layout Plain Layout

        self.present = mgng.MGNG(dimensions=dimensions,
\end_layout

\begin_layout Plain Layout

                                 gamma=int(prest_gamma),
\end_layout

\begin_layout Plain Layout

                                 lmbda=int(prest_lmbda),
\end_layout

\begin_layout Plain Layout

                                 theta=int(prest_theta),
\end_layout

\begin_layout Plain Layout

                                 alpha=float(prest_alpha),
\end_layout

\begin_layout Plain Layout

                                 beta=float(prest_beta),
\end_layout

\begin_layout Plain Layout

                                 delta=float(prest_delta),
\end_layout

\begin_layout Plain Layout

                                 eta=float(prest_eta),
\end_layout

\begin_layout Plain Layout

                                 e_w=float(prest_e_w),
\end_layout

\begin_layout Plain Layout

                                 e_n=float(prest_e_n))
\end_layout

\begin_layout Plain Layout

        self.past = mgng.MGNG(dimensions=dimensions,
\end_layout

\begin_layout Plain Layout

                              gamma=int(pst_gamma),
\end_layout

\begin_layout Plain Layout

                              lmbda=int(pst_lmbda),
\end_layout

\begin_layout Plain Layout

                              theta=int(pst_theta),
\end_layout

\begin_layout Plain Layout

                              alpha=float(pst_alpha),
\end_layout

\begin_layout Plain Layout

                              beta=float(pst_beta),
\end_layout

\begin_layout Plain Layout

                              delta=float(pst_delta),
\end_layout

\begin_layout Plain Layout

                              eta=float(pst_eta),
\end_layout

\begin_layout Plain Layout

                              e_w=float(pst_e_w),
\end_layout

\begin_layout Plain Layout

                              e_n=float(pst_e_n))
\end_layout

\begin_layout Plain Layout

        # self.buffer = deque(maxlen=self.buffer_len)
\end_layout

\begin_layout Plain Layout

        self.buffer = RingBuffer([[np.nan]*dimensions]*buffer_len)
\end_layout

\begin_layout Plain Layout

        if ma_window_len is None:
\end_layout

\begin_layout Plain Layout

            # self.ma_window = deque(maxlen=self.buffer_len)
\end_layout

\begin_layout Plain Layout

            self.ma_window = RingBuffer([np.nan]*buffer_len)
\end_layout

\begin_layout Plain Layout

        else:
\end_layout

\begin_layout Plain Layout

            # self.ma_window = deque(maxlen=ma_window_len)
\end_layout

\begin_layout Plain Layout

            self.ma_window = RingBuffer([np.nan]*ma_window_len)
\end_layout

\begin_layout Plain Layout

        self.ma_recalc_delay = ma_recalc_delay
\end_layout

\begin_layout Plain Layout

        self.anomaly_mean = None
\end_layout

\begin_layout Plain Layout

        self.anomaly_std = None
\end_layout

\begin_layout Plain Layout

        self.t = 0
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def time_step(self, xt):
\end_layout

\begin_layout Plain Layout

        xt = np.reshape(xt, newshape=self.dimensions)
\end_layout

\begin_layout Plain Layout

        ret_val = 0.
\end_layout

\begin_layout Plain Layout

        self.buffer.append(xt)
\end_layout

\begin_layout Plain Layout

        self.present.time_step(xt)
\end_layout

\begin_layout Plain Layout

        if self.t >= self.buffer_len:
\end_layout

\begin_layout Plain Layout

            pst_xt = self.buffer[0]
\end_layout

\begin_layout Plain Layout

            self.past.time_step(pst_xt)
\end_layout

\begin_layout Plain Layout

            if self.t >= self.present.theta + self.past.theta:
\end_layout

\begin_layout Plain Layout

                ret_val = self.comparison_function(self.present, self.past,
\end_layout

\begin_layout Plain Layout

                                                   self.present.alpha)
\end_layout

\begin_layout Plain Layout

        self.ma_window.append(ret_val)
\end_layout

\begin_layout Plain Layout

        if self.t % self.ma_recalc_delay == 0:
\end_layout

\begin_layout Plain Layout

            self.anomaly_mean = bn.nanmean(self.ma_window)
\end_layout

\begin_layout Plain Layout

            self.anomaly_std = bn.nanstd(self.ma_window, ddof=1)
\end_layout

\begin_layout Plain Layout

        if self.anomaly_mean is None:
\end_layout

\begin_layout Plain Layout

            anomaly_density = 0.5
\end_layout

\begin_layout Plain Layout

        else:
\end_layout

\begin_layout Plain Layout

            anomaly_density = norm.cdf(ret_val, loc=self.anomaly_mean,
\end_layout

\begin_layout Plain Layout

                                       scale=self.anomaly_std)
\end_layout

\begin_layout Plain Layout

        self.t += 1
\end_layout

\begin_layout Plain Layout

        return ret_val, anomaly_density
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def compare_models(present_model, past_model, alpha):
\end_layout

\begin_layout Plain Layout

    tot = [0.]
\end_layout

\begin_layout Plain Layout

    ps_w = past_model.weights
\end_layout

\begin_layout Plain Layout

    ps_c = past_model.contexts
\end_layout

\begin_layout Plain Layout

    for pr_x in present_model.model.node:
\end_layout

\begin_layout Plain Layout

        pr_x_w = present_model.weights[pr_x]
\end_layout

\begin_layout Plain Layout

        pr_x_c = present_model.contexts[pr_x]
\end_layout

\begin_layout Plain Layout

        # dists = ne.evaluate('sum((1-alpha)*(pr_x_w - ps_w)**2 +'
\end_layout

\begin_layout Plain Layout

        #                     '    alpha*(pr_x_c - ps_c)**2, axis=1)')
\end_layout

\begin_layout Plain Layout

        dists = np.add.reduce((1 - alpha)*(pr_x_w - ps_w)**2 +
\end_layout

\begin_layout Plain Layout

                              alpha*(pr_x_c - ps_c)**2, axis=1)
\end_layout

\begin_layout Plain Layout

        # print(dists)
\end_layout

\begin_layout Plain Layout

        ps_x = np.nanargmin(dists)
\end_layout

\begin_layout Plain Layout

        tot += dists[ps_x]
\end_layout

\begin_layout Plain Layout

    return tot[0] / len(present_model.model.nodes())
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def compare_models_w(present_model, past_model):
\end_layout

\begin_layout Plain Layout

    tot_w = [0.]
\end_layout

\begin_layout Plain Layout

    ps_w = past_model.weights
\end_layout

\begin_layout Plain Layout

    for pr_x in self.present.model.nodes():
\end_layout

\begin_layout Plain Layout

        pr_x_w = self.present.get_node(pr_x)['w']
\end_layout

\begin_layout Plain Layout

        dists = ne.evaluate('sum((pr_x_w - ps_w)**2, axis=1)')
\end_layout

\begin_layout Plain Layout

        ps_x = np.nanargmin(dists)
\end_layout

\begin_layout Plain Layout

        tot_w += dists[ps_x]
\end_layout

\begin_layout Plain Layout

    return tot_w[0] / len(self.present.model.nodes())
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def compare_models_c(present_model, past_model):
\end_layout

\begin_layout Plain Layout

    tot_c = [0.]
\end_layout

\begin_layout Plain Layout

    ps_c = past_model.contexts
\end_layout

\begin_layout Plain Layout

    for pr_x in self.present.model.nodes():
\end_layout

\begin_layout Plain Layout

        pr_x_c = self.present.get_node(pr_x)['c']
\end_layout

\begin_layout Plain Layout

        dists = ne.evaluate('sum((pr_x_c - ps_c)**2, axis=1)')
\end_layout

\begin_layout Plain Layout

        tot_c += dists[ps_x]
\end_layout

\begin_layout Plain Layout

    return tot_c[0] / len(self.present.model.nodes())
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def main(input_file, output_file, input_frame=None,
\end_layout

\begin_layout Plain Layout

         buffer_len=None, sampling_rate=None, index_col=None,
\end_layout

\begin_layout Plain Layout

         skip_rows=None, ma_window=None, ma_recalc_delay=1):
\end_layout

\begin_layout Plain Layout

    import pandas as pd
\end_layout

\begin_layout Plain Layout

    from datetime import datetime
\end_layout

\begin_layout Plain Layout

    if buffer_len is None:
\end_layout

\begin_layout Plain Layout

        buffer_len = 2000
\end_layout

\begin_layout Plain Layout

    if input_frame is None:
\end_layout

\begin_layout Plain Layout

        signal = pd.read_csv(input_file, index_col=index_col, parse_dates=True,
\end_layout

\begin_layout Plain Layout

                             skiprows=skip_rows)
\end_layout

\begin_layout Plain Layout

        if sampling_rate is not None:
\end_layout

\begin_layout Plain Layout

            signal = signal.resample(sampling_rate)
\end_layout

\begin_layout Plain Layout

    else:
\end_layout

\begin_layout Plain Layout

        signal = input_frame
\end_layout

\begin_layout Plain Layout

    if ma_window is None:
\end_layout

\begin_layout Plain Layout

        ma_window = len(signal)
\end_layout

\begin_layout Plain Layout

    print(signal.head())
\end_layout

\begin_layout Plain Layout

    print(signal.tail())
\end_layout

\begin_layout Plain Layout

    print('Seting up model.')
\end_layout

\begin_layout Plain Layout

    amgng = AMGNG(comparison_function=compare_models,
\end_layout

\begin_layout Plain Layout

                  buffer_len=buffer_len, dimensions=signal.shape[1],
\end_layout

\begin_layout Plain Layout

                  prest_gamma=buffer_len//2, prest_lmbda=buffer_len*6,
\end_layout

\begin_layout Plain Layout

                  prest_theta=buffer_len, pst_gamma=buffer_len//2,
\end_layout

\begin_layout Plain Layout

                  pst_lmbda=buffer_len*6, pst_theta=buffer_len,
\end_layout

\begin_layout Plain Layout

                  ma_window_len=ma_window, ma_recalc_delay=ma_recalc_delay)
\end_layout

\begin_layout Plain Layout

    scores = np.zeros(len(signal))
\end_layout

\begin_layout Plain Layout

    pscores = np.zeros(len(signal))
\end_layout

\begin_layout Plain Layout

    print('Processing {} rows'.format(len(signal)))
\end_layout

\begin_layout Plain Layout

    start = datetime.now()
\end_layout

\begin_layout Plain Layout

    for t, xt in enumerate(signal.values):
\end_layout

\begin_layout Plain Layout

        if t % (len(signal)//100) == 0:
\end_layout

\begin_layout Plain Layout

            print('{}% done.
 Sample datapoint: {}'
\end_layout

\begin_layout Plain Layout

                  .format(t / (len(signal)//100), xt))
\end_layout

\begin_layout Plain Layout

        scores[t], pscores[t] = amgng.time_step(xt)
\end_layout

\begin_layout Plain Layout

    time_taken = (datetime.now() - start).total_seconds()
\end_layout

\begin_layout Plain Layout

    print('It took {} seconds to process the signal'.format(time_taken))
\end_layout

\begin_layout Plain Layout

    signal['anomaly_score'] = pd.Series(scores, index=signal.index)
\end_layout

\begin_layout Plain Layout

    signal['anomaly_density'] = pd.Series(pscores, index=signal.index)
\end_layout

\begin_layout Plain Layout

    print('Writing results to {}'.format(output_file))
\end_layout

\begin_layout Plain Layout

    signal.to_csv(output_file)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

if __name__ == '__main__':
\end_layout

\begin_layout Plain Layout

    import sys
\end_layout

\begin_layout Plain Layout

    args = sys.argv
\end_layout

\begin_layout Plain Layout

    if '--input_file' in args:
\end_layout

\begin_layout Plain Layout

        input_file = args[args.index('--input_file') + 1]
\end_layout

\begin_layout Plain Layout

    else:
\end_layout

\begin_layout Plain Layout

        input_file = 'samples.csv'
\end_layout

\begin_layout Plain Layout

    if '--output_file' in args:
\end_layout

\begin_layout Plain Layout

        output_file = args[args.index('--output_file') + 1]
\end_layout

\begin_layout Plain Layout

    else:
\end_layout

\begin_layout Plain Layout

        output_file = '{}_out.csv'.format(input_file)
\end_layout

\begin_layout Plain Layout

    if '--buffer_len' in args:
\end_layout

\begin_layout Plain Layout

        buffer_len = int(args[args.index('--buffer_len') + 1])
\end_layout

\begin_layout Plain Layout

    else:
\end_layout

\begin_layout Plain Layout

        buffer_len = None
\end_layout

\begin_layout Plain Layout

    if '--sampling_rate' in args:
\end_layout

\begin_layout Plain Layout

        sampling_rate = args[args.index('--sampling_rate') + 1]
\end_layout

\begin_layout Plain Layout

    else:
\end_layout

\begin_layout Plain Layout

        sampling_rate = None
\end_layout

\begin_layout Plain Layout

    if '--index_col' in args:
\end_layout

\begin_layout Plain Layout

        index_col = args[args.index('--index_col') + 1]
\end_layout

\begin_layout Plain Layout

    else:
\end_layout

\begin_layout Plain Layout

        index_col = None
\end_layout

\begin_layout Plain Layout

    if '--skip_rows' in args:
\end_layout

\begin_layout Plain Layout

        skip_rows = args[args.index('--skip_rows') + 1].split(',')
\end_layout

\begin_layout Plain Layout

        skip_rows = [int(r) for r in skip_rows]
\end_layout

\begin_layout Plain Layout

    else:
\end_layout

\begin_layout Plain Layout

        skip_rows = None
\end_layout

\begin_layout Plain Layout

    print(args)
\end_layout

\begin_layout Plain Layout

    main(input_file, output_file, buffer_len, sampling_rate,
\end_layout

\begin_layout Plain Layout

         index_col, skip_rows)
\end_layout

\end_inset


\end_layout

\end_body
\end_document
